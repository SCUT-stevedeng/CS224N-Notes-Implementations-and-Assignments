{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac519109-e647-4576-bfdf-e9952e372f53",
   "metadata": {},
   "source": [
    "# How to Learn word vectors?\n",
    "\n",
    "## Gradient Descent\n",
    "\n",
    "### (Batch) Gradient Descent.\n",
    "Computing the cost of the entire training set and doing gradient descent.\n",
    "\n",
    "### Stochastic Gradient Descent\n",
    "Instead of computing the cost of the entire training set and doing gradient descent, stochastic gradient descent is using one training sample to compute the cost and doing gradient descent.\n",
    "\n",
    "### Mini-Batch Gradient Descent\n",
    "We have a compromise between Batch Gradient Descent and Stochastic Gradient Descent. That is Mini-Batch Gradient Descent, where we select a batch of a given batch size N (samples) to compute the cost. Following is the definition of these three gradient descent methods by batch size:\n",
    "Batch Gradient Descent: N = the size of the training set;\n",
    "Stochastic Gradient Descent: N = 1;\n",
    "Mini-Batch Gradient Descent: 1 < N < the size of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6fac4b-f488-432f-8e77-779fd190b5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
